# ğŸ¬ VideoAi â€” Local AI Video Generator

Generate videos from images using AI, **100% locally** on your Mac. Powered by [Stable Video Diffusion](https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt) with Apple Metal (MPS) acceleration.

![Python](https://img.shields.io/badge/Python-3.10+-blue?logo=python)
![Flask](https://img.shields.io/badge/Flask-3.0+-green?logo=flask)
![License](https://img.shields.io/badge/License-MIT-yellow)
![Platform](https://img.shields.io/badge/Platform-macOS%20Apple%20Silicon-black?logo=apple)

---

## âœ¨ Features

- ğŸ–¼ï¸ **Image-to-Video** â€” Upload any image, get an animated video
- ğŸŒ **Web UI** â€” Premium dark glassmorphism interface with drag & drop
- ğŸ **Apple Silicon optimized** â€” Runs on M1/M2/M3 with MPS backend
- ğŸ”’ **100% local & private** â€” No data leaves your machine
- âš¡ **Safety Presets** â€” One-click optimal settings for 8GB RAM
- ğŸ“Š **Real-time progress** â€” SSE-powered live progress bar
- ğŸï¸ **Video preview & download** â€” Built-in player with MP4 export

---

## ğŸš€ Quick Start

### Prerequisites
- macOS 12.6+ (13.0+ recommended)
- Python 3.10+
- Apple Silicon Mac (M1/M2/M3)

### Installation
```bash
git clone https://github.com/lukaphp/VideoAi.git
cd VideoAi
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
pip install torch torchvision diffusers transformers accelerate opencv-python imageio imageio-ffmpeg
```

### Run Web UI
```bash
source venv/bin/activate
python app.py
```
Open **http://localhost:5001** in your browser.

### Run CLI
```bash
# Default preset (recommended for 8GB RAM)
python generate_video.py photo.jpg

# Custom parameters
python generate_video.py photo.jpg --steps 25 --frames 14 --motion 80

# Minimal memory usage
python generate_video.py photo.jpg --width 256 --height 256 --frames 8 --steps 15
```

---

## âš™ï¸ Parameters

| Parameter | Default | Range | Description |
|:---|:---|:---|:---|
| Width | 448 | 256-1024 | Video width (multiples of 64) |
| Height | 256 | 256-1024 | Video height (multiples of 64) |
| Steps | 20 | 5-50 | Sampling steps (more = better quality) |
| Motion | 100 | 1-255 | Motion intensity |
| FPS | 6 | 2-30 | Frames per second |
| Frames | 10 | 4-25 | Number of frames |
| Seed | random | 0-999999999 | Reproducibility seed |

---

## ğŸ—ï¸ Architecture

```
Browser âŸ¶ Flask (app.py) âŸ¶ generate_video.py âŸ¶ SVD Pipeline (MPS)
              â”‚                                         â”‚
              â””â”€ SSE progress â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

```
VideoAi/
â”œâ”€â”€ app.py                 # Flask server + REST API
â”œâ”€â”€ generate_video.py      # SVD pipeline + CLI
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ plan.md                # Setup guide (Italian)
â”œâ”€â”€ guida_cloud_gpu.md     # Cloud GPU guide (Italian)
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ index.html         # Web UI
â”‚   â”œâ”€â”€ style.css          # Dark glassmorphism theme
â”‚   â””â”€â”€ app.js             # Frontend logic
â””â”€â”€ README.md
```

---

## ğŸ’¾ Memory Optimizations

This project uses aggressive optimizations to run on 8GB RAM:

- **Sequential CPU Offload** â€” Only 1 model component on GPU at a time
- **Attention Slicing (max)** â€” Chunked attention computation
- **UNet Forward Chunking** â€” Feedforward layers processed in chunks
- **Float16 precision** â€” Half the memory of float32
- **MPS High Watermark disabled** â€” Prevents premature OOM errors

---

## âš ï¸ Known Limitations

- **No text prompts** â€” SVD is image-to-video only (no text conditioning)
- **Slow on 8GB** â€” ~10 min per video due to CPU offloading
- **Short videos** â€” Max ~14 frames (2.3s at 6fps) on 8GB

---

## ğŸ“„ License

MIT License â€” free for personal and commercial use.
